{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequent Pattern Mining"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bước 1: Tiền xử lý dữ liệu ảnh. Lấy tên tệp và gán nó làm label cho tất cả các ảnh trong tệp đó. Chỉ sử dụng những ảnh đuôi .pgm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "data_dir = os.path.join(ROOT_DIR, \"CMU_FACE_Data/faces\")\n",
    "X = []  # Features\n",
    "y = []  # Labels\n",
    "size = (64, 64)\n",
    "\n",
    "for subdir in os.listdir(data_dir):\n",
    "    subdir_path = os.path.join(data_dir, subdir)\n",
    "    if not os.path.isdir(subdir_path):\n",
    "        continue\n",
    "\n",
    "    for file_name in os.listdir(subdir_path):\n",
    "        if not file_name.endswith(\".pgm\"):\n",
    "            continue\n",
    "\n",
    "        parts = file_name.split(\"_\")\n",
    "        user_id = parts[0]\n",
    "\n",
    "        file_path = os.path.join(subdir_path, file_name)\n",
    "        image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if image is not None:\n",
    "            X.append(image)\n",
    "            y.append(subdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['an2i' 'at33' 'boland' 'bpm' 'ch4f' 'cheyer' 'choon' 'danieln' 'glickman'\n",
      " 'karyadi' 'kawamura' 'kk49' 'megak' 'mitchell' 'night' 'phoebe' 'saavik'\n",
      " 'steffi' 'sz24' 'tammo']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(np.unique(y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bước 2: Triển khai một lớp gọi là \"LocalBinaryPatterns\" và một phương thức \"describe\" để tính toán biểu diễn Local Binary Pattern (LBP) của một hình ảnh.\n",
    "Phương thức \"describe\" nhận vào một hình ảnh và thực hiện các bước để tính toán biểu diễn LBP của hình ảnh đó. Các bước chính gồm:\n",
    "\n",
    "1. Sử dụng hàm \"local_binary_pattern\" từ module \"feature\" để tính toán LBP của hình ảnh. Các đối số của hàm bao gồm:\n",
    "\"image\": hình ảnh đầu vào.\n",
    "\"numPoints\": số lượng điểm mẫu sử dụng trong quá trình tính toán LBP.\n",
    "\"radius\": bán kính của vùng lân cận xung quanh mỗi điểm mẫu.\n",
    "\"method\": phương pháp tính toán LBP, trong trường hợp này là \"uniform\".\n",
    "Kết quả của bước này là một ma trận LBP.\n",
    "\n",
    "2. Sử dụng hàm \"histogram\" từ thư viện NumPy để xây dựng histogram của các mẫu LBP. Các đối số của hàm bao gồm:\n",
    "\"lbp.ravel()\": một mảng 1D chứa các giá trị LBP từ ma trận LBP.\n",
    "\"bins\": các khoảng giá trị để chia histogram, trong trường hợp này là từ 0 đến numPoints + 3.\n",
    "\"range\": khoảng giá trị của histogram, trong trường hợp này là từ 0 đến numPoints + 2.\n",
    "Kết quả của bước này là histogram của các mẫu LBP.\n",
    "\n",
    "Chuẩn hóa histogram bằng cách chia tất cả các giá trị trong histogram cho tổng của chúng cộng với một giá trị rất nhỏ (eps) để tránh chia cho 0.\n",
    "\n",
    "Trả về histogram của Local Binary Pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import feature\n",
    "\n",
    "class LocalBinaryPatterns:\n",
    "\tdef __init__(self, numPoints, radius):\n",
    "\t\tself.numPoints = numPoints\n",
    "\t\tself.radius = radius\n",
    "\n",
    "\tdef describe(self, image, eps=1e-7):\n",
    "\t\tlbp = feature.local_binary_pattern(image, self.numPoints,\n",
    "\t\t\tself.radius, method=\"uniform\")\n",
    "\t\t(hist, _) = np.histogram(lbp.ravel(),\n",
    "\t\t\tbins=np.arange(0, self.numPoints + 3),\n",
    "\t\t\trange=(0, self.numPoints + 2))\n",
    "\n",
    "\t\thist = hist.astype(\"float\")\n",
    "\t\thist /= (hist.sum() + eps)\n",
    "\n",
    "\t\treturn hist"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bước 3: Tạo một đối tượng desc từ lớp LocalBinaryPatterns với numPoints = 64 và radius = 8. Đối tượng này sẽ được sử dụng để tính toán biểu diễn LBP của các hình ảnh.\n",
    "\n",
    "Tiếp theo, ta khởi tạo một danh sách rỗng features để lưu trữ các đặc trưng LBP của các hình ảnh.\n",
    "\n",
    "Sau đó, trong vòng lặp for x in X, với X là một danh sách chứa các hình ảnh đầu vào, ta thực hiện các bước sau:\n",
    "\n",
    "1. Gọi phương thức describe của đối tượng desc để tính toán biểu diễn LBP của hình ảnh x. Kết quả được lưu vào biến f.\n",
    "2. Kiểm tra xem f có khác None hay không. Nếu khác None, tức là tính toán LBP thành công, ta thêm f vào danh sách features.\n",
    "\n",
    "Cuối cùng, sau khi vòng lặp kết thúc, danh sách features sẽ chứa các biểu diễn LBP của các hình ảnh trong X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = LocalBinaryPatterns(64, 8)\n",
    "\n",
    "features = []\n",
    "for x in X:\n",
    "    f = desc.describe(x)\n",
    "    if f is not None:\n",
    "        features.append(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bước 4: Sử dụng phương thức train_test_split để chia dữ liệu thành tập huấn luyện và tập kiểm tra với tỉ lệ 8 : 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bước 5: Sử dụng thư viện mlxtend để thực hiện phân tích mẫu phổ biến.\n",
    "\n",
    "1. Tạo một mảng X_arr từ danh sách train_frequent_patterns và chuyển đổi thành mảng numpy bằng np.array().\n",
    "2. Tạo DataFrame df từ mảng X_arr.\n",
    "3. Sử dụng df.applymap(str) để chuyển đổi tất cả các phần tử của DataFrame thành kiểu dữ liệu chuỗi (string).\n",
    "4. Sử dụng pd.get_dummies(df) để thực hiện mã hóa one-hot encoding trên DataFrame df. Kết quả là DataFrame one_hot_df với các cột được tạo ra từ các giá trị duy nhất trong DataFrame ban đầu.\n",
    "5. Sử dụng fpgrowth(one_hot_df, min_support=0.05, use_colnames=True) để áp dụng thuật toán FP-Growth trên DataFrame one_hot_df. Các đối số:\n",
    "    + min_support: ngưỡng hỗ trợ tối thiểu của mẫu phổ biến. Ở đây, ngưỡng là 0.05, tức là mẫu phổ biến phải xuất hiện ít nhất 5% trong tập dữ liệu.\n",
    "    + use_colnames: sử dụng tên cột thay vì chỉ số của cột trong kết quả mẫu phổ biến.\n",
    "    \n",
    "Kết quả trả về là DataFrame frequent_patterns chứa tập hợp các mẫu phổ biến cùng với giá trị hỗ trợ của chúng. Mỗi hàng đại diện cho một tập hợp  phổ biến, và cột \"itemsets\" chứa các mẫu tạo thành tập hợp. Giá trị hỗ trợ đại diện cho tỷ lệ giao dịch trong tập dữ liệu chứa tập hợp mẫu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "\n",
    "X_arr = np.array(X_train)\n",
    "df = pd.DataFrame(X_arr)\n",
    "df = df.applymap(str)\n",
    "\n",
    "one_hot_df = pd.get_dummies(df)\n",
    "frequent_patterns = fpgrowth(one_hot_df, min_support=0.05, use_colnames=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       support                            itemsets\n",
      "0     0.329993                            (54_0.0)\n",
      "1     0.219773                            (48_0.0)\n",
      "2     0.075484           (50_0.000260416666659885)\n",
      "3     0.066800            (51_0.00052083333331977)\n",
      "4     0.060120            (46_0.00052083333331977)\n",
      "...        ...                                 ...\n",
      "2422  0.052772  (26_0.0010416666665581597, 56_0.0)\n",
      "2423  0.056780  (26_0.0010416666665581597, 54_0.0)\n",
      "2424  0.050768  (26_0.0010416666665581597, 55_0.0)\n",
      "2425  0.055444  (23_0.0020833333331163194, 54_0.0)\n",
      "2426  0.057448  (34_0.0020833333331163194, 54_0.0)\n",
      "\n",
      "[2427 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(frequent_patterns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bước 6: Sử dụng mô hình RandomForestClassifier để phân loại.\n",
    "\n",
    "1. Tạo một đối tượng clf_rf từ lớp RandomForestClassifier với các đối số:\n",
    "    + n_estimators: số lượng cây quyết định trong mô hình Random Forest. Ở đây, ta đặt giá trị là 100.\n",
    "    + random_state: giá trị để đảm bảo sự phân chia ngẫu nhiên nhưng nhất quán. Ở đây, ta đặt giá trị là 42.\n",
    "2. Sử dụng phương thức fit(X_train, y_train) trên đối tượng clf_rf để huấn luyện mô hình RandomForestClassifier trên tập huấn luyện. Đối số X_train là tập đặc trưng huấn luyện và y_train là nhãn tương ứng.\n",
    "3. Sử dụng phương thức predict(X_test) trên đối tượng clf_rf để dự đoán nhãn cho tập kiểm tra X_test. Kết quả được lưu vào biến y_pred.\n",
    "\n",
    "Cuối cùng, ta có một mô hình RandomForestClassifier đã được huấn luyện và sử dụng để dự đoán nhãn cho tập kiểm tra X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "y_pred = clf_rf.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bước 7: Tính Accuracy và F1 Score.\n",
    "\n",
    "+ Độ chính xác (Accuracy): Độ chính xác được tính bằng cách so sánh nhãn thực tế (y_test) với nhãn dự đoán (y_pred) trên tập kiểm tra. Độ chính xác là tỷ lệ giữa số lượng dự đoán chính xác và tổng số mẫu. acc = TP + TN / (TP + TN + FP + FN)\n",
    "+ F1 Score: F1 Score là một số đo kết hợp giữa độ chính xác (precision) và độ phủ (recall) của mô hình. F1 Score là trung bình điều hoà của precision và recall, và được tính bằng công thức: F1 = 2 * (precision * recall) / (precision + recall).\n",
    "    Precision = TP / (TP + FP)\n",
    "    Recall = TP / (TP + FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.968\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9624784623849021\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(\"F1 Score:\", f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
